\documentclass[12pt]{article}
\usepackage[letterpaper, margin=0.25in]{geometry}
\usepackage{blindtext}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} 
\graphicspath{ {./images/} }
\usepackage{float} 
\usepackage{karnaugh-map}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{gensymb}
\usepackage{color, colortbl}

\newcommand{\foo}{\hspace{-2.3pt}$\bullet$ \hspace{5pt}}
\newcommand{\ts}{\textsuperscript}

\begin{document}
\title{\textbf{Preliminary Sensor Selection}}
\author{
  Alan Harris\\
  250901911
  \and
  Robert Potra\\
  250914807
  \and
  Andrew Randell\\
  250911270
  \and
  Kevin Wang\\
  250908180
}
\date{\today}
\maketitle

\setcounter{page}{1}

\section{Introduction}

To perform the task autonomously the robot requires information about its surroundings. Sensors are used to relay information about the changing environment to help the robot make decisions. The entire problem was divided into tasks that require different sensing capabilities, and therefore, the tasks include tracking the robot's position relative to the perimeter, detecting the tesseract, detecting the pyramid, and tracking the robot's position for outdoor applications. Key requirements for each task were outlined in Report 1.


\section{Sensor Specifications}
\subsection{Concept Generation}
\clearpage
% Table generated by Excel2LaTeX from sheet 'GONOGO'
\begin{table}[H]
  \centering
  \caption{GO/NO GO Table (\textit{"1" = GO, " " = NO GO)}}
    \begin{tabular}{p{15.645em}|c|c|c|c|c|c|c|c|c|c|c}
    \multicolumn{1}{r}{} & \multicolumn{1}{c}{\begin{sideways}\textbf{Range}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Accuracy}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Sensitivity}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Sample Rate}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Stability}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Repeatability}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Linearity}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Implementation Ease}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Elegance}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Long Life}\end{sideways}} & \begin{sideways}\textbf{Non-Contact}\end{sideways} \\
    \midrule
    \textbf{Local Position} &       &       &       &       &       &       &       &       &       &       &  \\
    LVDT (probes) &       & 1     & 1     & 1     & 1     & 1     & 1     &       &       & 1     &  \\
\rowcolor{green}    Ultrasonic & 1     & 1     &       & 1     & 1     & 1     & 1     & 1     & 1     & 1     & 1 \\
    Potentiometer (probes) &       & 1     & 1     & 1     & 1     & 1     & 1     &       &       &       &  \\
    Limit Switch (bump into walls) &       &       &       &       &       & 1     &       & 1     &       &       &  \\
    Capacitive &       &       &       & 1     &       &       &       &       &       & 1     & 1 \\
    Encoders (on wheels) & 1     &       &       & 1     &       &       & 1     & 1     & 1     & 1     & 1 \\
    \multicolumn{1}{r|}{} &       &       &       &       &       &       &       &       &       &       &  \\
    \midrule
    \textbf{Global Position} &       &       &       &       &       &       &       &       &       &       &  \\
\rowcolor{green}    GNSS  & 1     & 1     &       &       &       &       & 1     & 1     & 1     & 1     & 1 \\
    RADAR & 1     & 1     & 1     &       & 1     & 1     & 1     &       & 1     & 1     & 1 \\
    SONAR &       &       &       &       &       & 1     & 1     &       & 1     & 1     & 1 \\
\rowcolor{green}    LIDAR & 1     & 1     & 1     & 1     & 1     & 1     & 1     &       & 1     & 1     & 1 \\
    Computer Vision & 1     & 1     & 1     & 1     & 1     & 1     & 1     &       & 1     & 1     & 1 \\
    \multicolumn{1}{r|}{} &       &       &       &       &       &       &       &       &       &       &  \\
    \midrule
    \textbf{Tesseract Detection} &       &       &       &       &       &       &       &       &       &       &  \\
    Hall Effect &       & 1     &       & 1     &       &       & 1     & 1     & 1     & 1     & 1 \\
\rowcolor{green}    Magnetometer & 1     & 1     & 1     & 1     &       & 1     & 1     & 1     & 1     & 1     & 1 \\
    Reed Switch &       &       &       &       &       & 1     &       &       &       &       & 1 \\
    Computer Vision & 1     &       &       &       &       &       &       &       & 1     & 1     & 1 \\
    \multicolumn{1}{r|}{} &       &       &       &       &       &       &       &       &       &       &  \\
    \midrule
    \textbf{Pyramid Detection} &       &       &       &       &       &       &       &       &       &       &  \\
\rowcolor{green}    IR Receiver & 1     & 1     &       & 1     &       &       & 1     & 1     & 1     & 1     & 1 \\
    Computer Vision & 1     &       &       &       &       &       &       &       & 1     & 1     & 1 \\
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%




\subsection{Local Position}
\subsubsection{Concept Selection}
LVDT, Potentiometer, and Limit Switch were eliminated first because of the dependence on physical contact with the surroundings. These are not feasible as contacting the wall will quickly wear the sensors, and may also endanger the robot as well as nearby people. In addition, the range is far too small, and should not be limited to a simple binary contact.
Encoders on the wheels were ruled out as there is a strong dependence on full traction of the wheels. The slightest loss of grip will throw off the sensors entirely, and will give inaccurate readings.
Capacitive Sensors were eliminated because the scale of the measurements is far too small for the size of the robot. Considering that the wall area is quite large, a capacitive sensor will not be able to provide the range necessary to accurately detect local position.
The chosen sensors are ultrasonic sensors, highlighted in green.


\subsection{Tesseract Detection}
Tesseract detection is an important function which the robot must perform. There are four main sensors which will be considered for the tesseract detection function—Hall Effect, magnetometer, reed switch and computer vision. 
The Hall Effect sensor is a standard sensor which excels in proximity sensing, position, speed detection and current sensing applications. However, hall effect sensor has a lower measuring accuracy and sensitivity—which is an important factor for improving the robot’s functionality—and the output signal tends to drift. 
The magnetometer is a sensor that measures the magnitude of a magnetic field.  For the tesseract detection application, a vector-based magnetometer will be used instead of scalar. A specific vector magnetometer is the fluxgate magnetometer. This sensor delivers the second highest level of sensitivity and dynamic range, while keeping noises and temperature drift low. Having a magnetic core and compensation coil, this sensor delivers high accuracy and low leakage.  
The reed switch is an electrical switch which is operated by a magnetic field. The switch is actuated when a magnet is brought near the switch. The reed switch operates with a parallel magnetic field, unlike hall effect which operates on a perpendicular magnetic field. Due to the mechanical parts of the reed switch the life expectancy is lower. The range and sensitivity are also lower compared to the other sensors due to its parallel sensing orientation. 


\subsection{Pyramid Detection}
In order to decode the infrared (IR) signal sent by the pyramid, an IR sensor will be used.  IR sensors excels in this application because of its ability pick up signals in a large area. This is a useful quality as it makes pyramid detection easier, especially used in conjunction with  GNSS. IR sensors also have high repeatability and provide good stability over time. An important note for this sensor is that the transmitter and receiver must be in line of sight (LOS). The final design of the robot must ensure that the IR sensor is in LOS with the transmitter.

\subsection{Global Position}
From a macro perspective, the vehicle will need to know an approximate location of where it is on a map, as well as the approximate locations of pyramid(s) and tesseracts. \\

\paragraph{GNSS} (Global Navigation Satellite System) is the global positioning technology that is applicable. GNSS is a generic world-wide term used to describe satellite navigation systems. The specific technology used is dependant on the region where it is being used. Regional tecnologies include GPS, GLONASS, Beidou, and Galileo.  This technology provides \textit{approximate} latitude, longitude, and altitude metrics to their host device. 

\paragraph{Hardware Implementation} of GNSS on devices is very straight forward with GNSS Modules. These modules are integrated GNSS receivers which can easily be implemented onto devices. They generally require a power input and provide NMEA 0183 GNSS coordinates over a UART connection. A table below has been compiled of high ranking GNSS modules. The controller must support UART communication for compatibility with most GNSS modules.

\clearpage
\section{Project Timeline}
Our team was able to follow the project timeline specified in our previous report. As a result, we have decided to keep the same timeline, with updated dates. Should our team encounter difficulty following the timeline, updates will be made in future reports to reflect the current state of work.\\
\begin{flushleft}
\textit{Week of:}

\begin{tabular}{l | l}


 
\textbf{Feb. 11} &\textbf{Preliminary Sensor Selection Deliverable: Step 2 Due Feb. 15\ts{th}}\\
 & $\bullet$ Prepare and finalize report for step 2 deliverable\\\\
 
\textbf{Feb. 18} &\textbf{Research Applicable Actuators}\\
 & $\bullet$ Restate and redefine actuator specifications\\
  & $\bullet$ Identify possible actuator options based on previous concepts\\\\
  
\textbf{Feb. 25} & \textbf{Continue Actuator Design}\\
 & $\bullet$ Concept generation using possible actuator options\\
  & $\bullet$ Refine logic connecting the sensor data to actuator actions\\\\
  
\textbf{Mar. 04} & \textbf{Finalize Actuator Simulations}\\
 & $\bullet$ Perform actuator simulations using Simulink\\
 & $\bullet$ Begin preparing report for step 3 deliverable\\
 & $\bullet$ Perform concept selection using actuator simulation results and analysis\\\\
 
\textbf{Mar. 11} &\textbf{Preliminary Actuator Selection Deliverable: Step 3 Due Mar. 15\ts{th}}\\
 & $\bullet$ Continue preparing and finalize report step 3 deliverable\\\\
 
\textbf{Mar. 18} & \textbf{Evaluate Sensor and Actuators}\\
 & $\bullet$ Evaluate the proposed system of sensors and actuators\\
  & $\bullet$ Create a kinematic system model and perform analysis using Solidworks\\\\
  
\textbf{Mar. 25} & \textbf{Obtain Feedback and Iterate}\\
  & $\bullet$ Identify possible problems with the proposed system of sensors and actuators\\
  & $\bullet$ Refine analysis for the transducers, control device, kinematics, and power supply\\\\
  
\textbf{Apr. 01} & \textbf{Finalize Final Simulations and Report: Step 4 Due Apr. 5\ts{th}}\\
 & $\bullet$ Continue preparing final report for step 4 deliverable\\

\end{tabular}
\end{flushleft}


\end{document}