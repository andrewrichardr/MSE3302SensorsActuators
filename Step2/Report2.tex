\documentclass[12pt]{article}
\usepackage[letterpaper, margin=0.75in]{geometry}
\usepackage{blindtext}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} 
\graphicspath{ {./} }
\usepackage{float} 
\usepackage{karnaugh-map}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{gensymb}
\usepackage{color, colortbl}

\newcommand{\foo}{\hspace{-2.3pt}$\bullet$ \hspace{5pt}}
\newcommand{\ts}{\textsuperscript}

\begin{document}
\title{\textbf{Tesseract Project Revisit\\Preliminary Sensor Selection\\ MSE 3302 B}}
\author{
  Alan Harris\\
  250901911
  \and
  Robert Potra\\
  250914807
  \and
  Andrew Randell\\
  250911270
  \and
  Kevin Wang\\
  250908180
}
\date{\today}
\maketitle

\tableofcontents
\thispagestyle{empty}

\pagebreak
\setcounter{page}{1}

\section{Introduction}

To perform the task autonomously the robot requires information about its surroundings. Sensors are used to relay information about the changing environment to help the robot make decisions. The entire problem was divided into tasks that require different sensing capabilities, and therefore, the tasks include tracking the robot's position relative to the perimeter, detecting the tesseract, detecting the pyramid, and tracking the robot's position for outdoor applications. Key requirements for each task include:

\section{Sensor Specifications}

% Table generated by Excel2LaTeX from sheet 'GONOGO'
\begin{table}[H]
  \centering
  \caption{GO/NOGO Diagram, \textit{("1" = GO, " " = NOGO)}}
    \begin{tabular}{p{15.645em}|c|c|c|c|c|c|c|c|c|c|c}
    \multicolumn{1}{r}{} & \multicolumn{1}{c}{\begin{sideways}\textbf{Range}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Accuracy}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Sensitivity}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Sample Rate}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Stability}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Repeatability}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Linearity}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Implementation Ease}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Elegance}\end{sideways}} & \multicolumn{1}{c}{\begin{sideways}\textbf{Long Life}\end{sideways}} & \begin{sideways}\textbf{Non-Contact}\end{sideways} \\
    \midrule
    \textbf{Local Position} &       &       &       &       &       &       &       &       &       &       &  \\
    LVDT (probes) &       & 1     & 1     & 1     & 1     & 1     & 1     &       &       & 1     &  \\
    Ultrasonic & 1     & 1     &       & 1     & 1     & 1     & 1     & 1     & 1     & 1     & 1 \\
    Potentiometer (probes) &       & 1     & 1     & 1     & 1     & 1     & 1     &       &       &       &  \\
    Limit Switch (bump into walls) &       &       &       &       &       & 1     &       & 1     &       &       &  \\
    Capacitive &       &       &       & 1     &       &       &       &       &       & 1     & 1 \\
    Encoders (on wheels) & 1     &       &       & 1     &       &       & 1     & 1     & 1     & 1     & 1 \\
    RADAR & 1     & 1     & 1     &       & 1     & 1     & 1     &       & 1     & 1     & 1 \\
    SONAR &       &       &       &       &       & 1     & 1     &       & 1     & 1     & 1 \\
    LIDAR & 1     & 1     & 1     & 1     & 1     & 1     & 1     &       & 1     & 1     & 1 \\
    Computer Vision & 1     & 1     & 1     & 1     & 1     & 1     & 1     &       & 1     & 1     & 1 \\
    \multicolumn{1}{r|}{} &       &       &       &       &       &       &       &       &       &       &  \\
    \midrule
    \textbf{Global Position} &       &       &       &       &       &       &       &       &       &       &  \\
    GNSS  & 1     & 1     &       &       &       &       & 1     & 1     & 1     & 1     & 1 \\
    \multicolumn{1}{r|}{} &       &       &       &       &       &       &       &       &       &       &  \\
    \midrule
    \textbf{Tesseract Detection} &       &       &       &       &       &       &       &       &       &       &  \\
    Hall Effect &       & 1     &       & 1     &       &       & 1     & 1     & 1     & 1     & 1 \\
    Magnetometer & 1     & 1     & 1     & 1     &       & 1     & 1     & 1     & 1     & 1     & 1 \\
    Reed Switch &       &       &       &       &       & 1     &       &       &       &       & 1 \\
    Computer Vision & 1     &       &       &       &       &       &       &       & 1     & 1     & 1 \\
    \multicolumn{1}{r|}{} &       &       &       &       &       &       &       &       &       &       &  \\
    \midrule
    \textbf{Pyramid Detection} &       &       &       &       &       &       &       &       &       &       &  \\
    IR Receiver & 1     & 1     &       & 1     &       &       & 1     & 1     & 1     & 1     & 1 \\
    Computer Vision & 1     &       &       &       &       &       &       &       & 1     & 1     & 1 \\
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%



\subsection{Local Position}
\subsubsection{Concept Selection}
LVDT, Potentiometer, and Limit Switch were eliminated first because of the dependence on physical contact with the surroundings. These are not feasible as contacting the wall will quickly wear the sensors, and may also endanger the robot as well as nearby people. In addition, the range is far too small, and should not be limited to a simple binary contact.\\\\
Encoders on the wheels were ruled out as there is a strong dependence on full traction of the wheels. The slightest loss of grip will throw off the sensors entirely, and will give inaccurate readings.\\\\
Capacitive Sensors were eliminated because the scale of the measurements is far too small for the size of the robot. Considering that the wall area is quite large, a capacitive sensor will not be able to provide the range necessary to accurately detect local position.\\\\
Finally, RADAR, SONAR and Computer Vision were eliminated as the implementation of these systems is quite complicated and costly. While they perform well on the GO/NO GO screening, they fall short in comparison to the selected sensors. \\\\
The chosen sensors are ultrasonic, as well as LIDAR. 


\subsection{Tesseract Detection}
Tesseract detection is an important function which the robot much perform. There are four main sensors which will be considered for the tesseract detection function—Hall Effect, magnetometer, reed switch and computer vision. 
The Hall Effect sensor is a standard sensor which excels in proximity sensing, position, speed detection and current sensing applications. However, hall effect sensor has a lower measuring accuracy and sensitivity—which is an important factor for improving the robot’s functionality—and the output signal tends to drift. 
The magnetometer is a magnetic sensor which is an instrument that measure magnetism. For the tesseract detection application, a vector-based magnetometer will be used apart from a scalar. A specific vector magnetometer is the fluxgate magnetometer. This sensor delivers the second highest level of sensitivity and dynamic range, while keeping noises and temperature drift low. Having a magnetic core and compensation coil, this sensor delivers high accuracy and low leakage.  
The reed switch is an electrical switch which is operated by a magnetic field. The switch is actuated when a magnet is brought near the switch. The reed switch operates with a parallel magnetic field, unlike hall effect which operates on a perpendicular magnetic field. Due to the mechanical parts of the reed switch the life expectancy is lower. The range and sensitivity also lower compared to the other sensors due to its parallel sensing orientation. 


\subsection{Pyramid Detection}
In order to decode the infrared (IR) signal sent by the pyramid, an IR sensor will be used.  IR sensors excels in this application because of its ability to be applied to a large area. This is a useful quality as it makes pyramid detection easier, especially with conjunction of global positioning. IR sensors also have high repeatability and provide good stability over time these are all important qualifications for “large…”. An important note for this sensor is that the transmitter and receiver must be in line of sight (LOS). For the final design, final design of the robot must ensure that the IR sensor is in LOS with the transmitter and there are not obstructions in the LOS. 

\subsection{Global Position}
From a macro perspective, the vehicle will need to know an approximate location of where it is on a map, as well as the approximate locations of pyramid(s) and tesseracts. 

\paragraph{GNSS} (Global Navigation Satellite System) is the global positioning technology that is applicable. GNSS is a generic world-wide term used to describe satellite navigation systems. The specific technology used is dependant on the region where it is being used. Regional tecnologies include GPS, GLONASS, Beidou, and Galileo.  This technology provides \textit{approximate} latitude, longitude, and altitude metrics to their host device. 

\paragraph{Hardware Implementation} of GNSS on devices is very straight forward with GNSS Modules. These modules are integrated GNSS receivers which can easily be implemented onto devices. They generally require a power input and provide NMEA 0183 GNSS coordinates over a UART connection. A table below has been compiled of high ranking GNSS modules. The controller must support UART communication for compatibility with most GNSS modules.

\paragraph{Software Implementation} will require prior mapping of the power plant. The GNSS will provide approximate coordinates on this software map. This will be used in conjunction with local sensing techniques to make informed decisions about the locations of the autonomous system relative to the tesseract and pyramid(s).


\section{Controller}

\subsection{Navigational Map} The robot completes a survey of the area creating a software map in memory. All sensor readings are included in this survey. After the survey has been completed, the system will have a map of the area in which it operates. This map will continuously be updated as the system operates. The map can by used for autonomous navigation.

\section{Modeling}

\clearpage
\section{Project Timeline}

\begin{flushleft}
\textit{Week of:}

\begin{tabular}{l | l}


 
\textbf{Feb. 11} &\textbf{Preliminary Sensor Selection Deliverable: Step 2 Due Feb. 15\ts{th}}\\
 & $\bullet$ Prepare and finalize report for step 2 deliverable\\\\
 
\textbf{Feb. 18} &\textbf{Research Applicable Actuators}\\
 & $\bullet$ Restate and redefine actuator specifications\\
  & $\bullet$ Identify possible actuator options based on previous concepts\\\\
  
\textbf{Feb. 25} & \textbf{Continue Actuator Design}\\
 & $\bullet$ Concept generation using possible actuator options\\
  & $\bullet$ Refine logic connecting the sensor data to actuator actions\\\\
  
\textbf{Mar. 04} & \textbf{Finalize Actuator Simulations}\\
 & $\bullet$ Perform actuator simulations using Simulink\\
 & $\bullet$ Begin preparing report for step 3 deliverable\\
 & $\bullet$ Perform concept selection using actuator simulation results and analysis\\\\
 
\textbf{Mar. 11} &\textbf{Preliminary Actuator Selection Deliverable: Step 3 Due Mar. 15\ts{th}}\\
 & $\bullet$ Continue preparing and finalize report step 3 deliverable\\\\
 
\textbf{Mar. 18} & \textbf{Evaluate Sensor and Actuators}\\
 & $\bullet$ Evaluate the proposed system of sensors and actuators\\
  & $\bullet$ Create a kinematic system model and perform analysis using Solidworks\\\\
  
\textbf{Mar. 25} & \textbf{Obtain Feedback and Iterate}\\
  & $\bullet$ Identify possible problems with the proposed system of sensors and actuators\\
  & $\bullet$ Refine analysis for the transducers, control device, kinematics, and power supply\\\\
  
\textbf{Apr. 01} & \textbf{Finalize Final Simulations and Report: Step 4 Due Apr. 5\ts{th}}\\
 & $\bullet$ Continue preparing final report for step 4 deliverable\\

\end{tabular}
\end{flushleft}


\end{document}